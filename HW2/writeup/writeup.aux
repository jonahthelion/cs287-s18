\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem Description}{1}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Model and Algorithms}{1}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Evaluation}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{2}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Trigram}{2}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}NN Language Model}{2}{subsection.4.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  The first entry of $\alpha $ corresponds to ternary counts, and the third entry cooresponds to unary counts. The binary and ternary counts both contain considerably more information than unary.\relax }}{3}{table.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:interp}{{1}{3}{The first entry of $\alpha $ corresponds to ternary counts, and the third entry cooresponds to unary counts. The binary and ternary counts both contain considerably more information than unary.\relax }{table.caption.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  The NN does about the same on its own independent of $lookback$. The ensemble with Trigram waited by 0.643 and NN weighted 1-0.643 achieves higher accuracy than the Trigram model on its own.\relax }}{3}{table.caption.2}}
\newlabel{tab:NN}{{2}{3}{The NN does about the same on its own independent of $lookback$. The ensemble with Trigram waited by 0.643 and NN weighted 1-0.643 achieves higher accuracy than the Trigram model on its own.\relax }{table.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Training the NN with $lookback=3$\relax }}{3}{figure.caption.3}}
\newlabel{fig:clusters}{{1}{3}{Training the NN with $lookback=3$\relax }{figure.caption.3}{}}
\bibstyle{apalike}
\bibdata{writeup}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces  \relax }}{4}{table.caption.4}}
\newlabel{tab:conc}{{3}{4}{\relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}LSTM language model}{4}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Embedding $\rightarrow $ Embedding}{4}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}ResNet}{4}{subsection.4.5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{4}{section.5}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces  \relax }}{4}{table.caption.5}}
\newlabel{tab:conc}{{4}{4}{\relax }{table.caption.5}{}}
